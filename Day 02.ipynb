{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProblemInput:\n",
    "  reports: list[list[int]]\n",
    "  \n",
    "  @classmethod\n",
    "  def parse_input(cls, input: str) -> 'ProblemInput':\n",
    "    reports = []\n",
    "    for report in input.splitlines():\n",
    "      reports.append([int(l) for l in report.split(' ')])\n",
    "    return ProblemInput(reports)\n",
    "  \n",
    "  \n",
    "def sign(x: int) -> bool:\n",
    "  return x > 0\n",
    "\n",
    "\n",
    "def drop_level(report: list[int], i: int) -> list[int]:\n",
    "  return report[:i] + report[i+1:]\n",
    "  \n",
    "\n",
    "def is_safe(report: list[int]) -> bool:\n",
    "  \"\"\"\n",
    "  >>> is_safe([7, 6, 4, 2, 1])\n",
    "  True\n",
    "  >>> is_safe([1, 3, 2])\n",
    "  False\n",
    "  \"\"\"\n",
    "  if len(report) <= 1:\n",
    "    return True\n",
    "  \n",
    "  diffs = [r - l for (l, r) in zip(report[:-1], report[1:])]\n",
    "  incr = sign(diffs[0])\n",
    "  return all(1 <= abs(d) <= 3 and sign(d) == incr\n",
    "             for d in diffs)\n",
    "\n",
    "\n",
    "def is_safe_with_dampener(report: list[int]) -> bool:\n",
    "  \"\"\"\n",
    "  >>> is_safe_with_dampener([7, 6, 4, 2, 1])\n",
    "  True\n",
    "  >>> is_safe_with_dampener([1, 3, 2])\n",
    "  True\n",
    "  >>> is_safe_with_dampener([1, 3, 7, 8])\n",
    "  False\n",
    "  \"\"\"\n",
    "  return any(is_safe(drop_level(report, i))\n",
    "             for i in range(len(report)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_safe(p: ProblemInput, safety_fn=is_safe) -> int:\n",
    "  return sum(safety_fn(r) for r in p.reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=False, report=True, exclude_empty=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"\"\"7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\"\"\"\n",
    "\n",
    "problem = ProblemInput.parse_input(test_input)\n",
    "assert count_safe(problem, safety_fn=is_safe) == 2, \"p1 test failed\"\n",
    "assert count_safe(problem, safety_fn=is_safe_with_dampener) == 4, \"p2 test failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1:  534\n",
      "Part 2:  577\n"
     ]
    }
   ],
   "source": [
    "# Final answers\n",
    "with open('inputs/day02.txt') as f:\n",
    "    problem = ProblemInput.parse_input(f.read().strip())\n",
    "    print('Part 1: ', count_safe(problem, safety_fn=is_safe))\n",
    "    print('Part 2: ', count_safe(problem, safety_fn=is_safe_with_dampener))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
